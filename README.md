# cf_ai_minimal_app

Minimal Cloudflare AI chat app using Workers AI (Llama), Durable Objects for memory, and a simple HTML UI.

## Requirements
- Node.js 18+
- `wrangler` (installed via devDependencies)
- Cloudflare account with Workers + AI enabled

## Features
- LLM: Workers AI Llama instruct model (configurable via `MODEL` var)
- Workflow/coordination: Durable Object `ChatRoom`
- User input: basic web chat UI served by the Worker
- Memory/state: last 20 messages persisted per room in Durable Object storage

## Quickstart
```bash
# Install deps
npm install

# Dev (opens at http://localhost:8787)
npm run dev

# Deploy to Cloudflare (requires login)
npm run deploy
```

### Configure Model
Default model is set in `wrangler.toml` as `MODEL`. To override at deploy time:
```bash
wrangler deploy --var MODEL=@cf/meta/llama-3.3-8b-instruct
```

## Files
- `wrangler.toml`: Worker config, AI binding, Durable Object binding
- `src/index.ts`: Worker entry + `ChatRoom` Durable Object
- `public/`: Static assets (currently unused; UI is inline HTML for simplicity)
- `README.md`: This file
- `PROMPTS.md`: Prompts used during development

## Local Usage
- Open `http://localhost:8787`
- Type a message and press Enter or click Send
- Responses are generated by Workers AI and conversation context is stored in the Durable Object

## Deploy
Make sure you are logged in:
```bash
npx wrangler login
npm run deploy
```

## Repo naming requirement
Per instructions, name your GitHub repository with the prefix `cf_ai_` (e.g., `cf_ai_minimal_app`).

## Notes
- This project intentionally keeps the UI minimal to satisfy the assignment requirements without extra complexity.
